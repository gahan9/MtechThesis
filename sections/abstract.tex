
\addtotoc{Abstract} 
\abstract{
\addtocontents{toc}{\vspace{1em}}  

Handling huge volumes of data is always tricky in an enterprise environment especially when there are multiple data sources. Integrating data from these data sources to make some logical inference has always been a challenge. Integrating these data in a lot of way will reduce human intervention and eliminate the use of various tools to accomplish similar task. 

Aggregation of data becomes complex when the size of the data increases exponentially every day. The complexity further increases when the data has to be captured, analyzed and projected in real time. Existing ETL method of data extraction and mining works perfectly with historical records â€“ records that are either pre-stored or updated over longer intervals of time. When analysis is required to be performed on near real-time data, this method does not suit our need. This is mainly because; we try to transform the data intermediality - which increases the loading time. Instead, in this paper we propose a near real-time analysis platform that will load the data as and when available at a much higher rate which is later used for analytics/transformation.

}

\clearpage  